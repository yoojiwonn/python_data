{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoojiwonn/python_data/blob/main/tf_keras_DNN_iris_YJW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYWPrHpHvOaT",
        "outputId": "20d54855-f1e9-4bc5-e0c6-5a3846921bc7"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')   # google drive를 google colab에 연결. 처음 실행 시, 인증 필요 "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22UZuhWkLtVt"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers  # 모듈(변수나 함수를 포함)만 불러오기\n",
        "\n",
        "# BMI 데이터를 읽어 들이고 정규화하기\n",
        "dir = \"/content/gdrive/My Drive/Colab Notebooks/ai/\"  ### [중요!!] Colab의 경우, bmi.csv를 저장할 위치를 기록하시오.\n",
        "df = pd.read_csv(dir + \"iris.csv\")    ### [중요!!] https://github.com/jjyjung/ai/blob/gh-pages/bmi.csv 에서 다운받을 수 있습니다."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GAFF1QOk58E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ba5586e4-95f7-4c28-939d-a7b4f587e20f"
      },
      "source": [
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width        iris_type\n",
              "0             6.4          3.1           5.5          1.8   Iris-virginica\n",
              "1             6.5          3.0           5.8          2.2   Iris-virginica\n",
              "2             4.6          3.1           1.5          0.2      Iris-setosa\n",
              "3             6.4          2.8           5.6          2.1   Iris-virginica\n",
              "4             5.0          3.3           1.4          0.2      Iris-setosa\n",
              "..            ...          ...           ...          ...              ...\n",
              "145           5.1          3.8           1.9          0.4      Iris-setosa\n",
              "146           5.7          2.8           4.5          1.3  Iris-versicolor\n",
              "147           6.9          3.1           5.4          2.1   Iris-virginica\n",
              "148           7.2          3.0           5.8          1.6   Iris-virginica\n",
              "149           4.9          3.0           1.4          0.2      Iris-setosa\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c0a95b8-3eca-4833-ba1c-882ff98cee48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>iris_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.5</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.4</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>5.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>7.2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c0a95b8-3eca-4833-ba1c-882ff98cee48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c0a95b8-3eca-4833-ba1c-882ff98cee48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c0a95b8-3eca-4833-ba1c-882ff98cee48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaC6EJH_kwwz"
      },
      "source": [
        "# 몸무게와 키 데이터\n",
        "df[\"sepal_length\"] /= 100   # normalization\n",
        "df[\"sepal_width\"] /= 200   # normalization\n",
        "df[\"petal_length\"] /= 200   # normalization\n",
        "df[\"petal_width\"] /= 200   # normalization\n",
        "# X = df[[\"sepal_lenth\", \"sepal_width\",\"petal_length\",\"petal_width\"]].to_numpy()\n",
        "X = df.iloc[:,0:4]\n",
        "df\n",
        "# 레이블링, 라벨링 (labelling) => one-hot encoding\n",
        "bclass = {\"Iris-setosa\":[1,0,0], \"Iris-virginica\":[0,1,0], \"Iris-versicolor\":[0,0,1]}\n",
        "y = np.empty((150,3))     # 150x3 크기의 다차원 벡터 생성\n",
        "for i, v in enumerate(df[\"iris_type\"]):\n",
        "    y[i] = bclass[v]        # \"Iris-virginica\"이면, y[i]=[1,0,0] 와 같이 할당\n",
        "    \n",
        "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기\n",
        "X_train, y_train = X[0:100], y[0:100]\n",
        "X_test,  y_test  = X[100:150], y[100:150]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "G2UgYhccLtVu"
      },
      "source": [
        "# 모델 구조 정의하기\n",
        "model = tf.keras.Sequential()         # 순차적 계층화 준비\n",
        "model.add(layers.Dense(8, input_shape=(4,)))  # 입력 4개로부터 전달받는 9개 노드의 layer 생성\n",
        "model.add(layers.Activation('relu'))  # ReLU 활성화함수 채택\n",
        "model.add(layers.Dropout(0.1))        # dropout ratio=10% (배치 훈련시 10% arc 무시)\n",
        "\n",
        "model.add(layers.Dense(4))            # 4개 노드의 layer 생성\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "model.add(layers.Dense(3))\n",
        "model.add(layers.Activation('softmax'))# 분류(classification)을 위해 softmax 함수 사용\n",
        "# model.add(layers.Dropout(0.1))\n",
        "\n",
        "\n",
        "# 모델 구축하기\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',  # 다중 교차엔트로피\n",
        "    optimizer=\"rmsprop\",   # 최적화 기법 중 하나\n",
        "    metrics=['accuracy'])  # 정확도 측정"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2IhHchdXLtVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906ffebd-aac3-4cdd-ab9c-fae5eef753d0"
      },
      "source": [
        "# 데이터 훈련하기\n",
        "hist = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=3,     # 3개에 한 번씩 업데이터 실행\n",
        "    epochs=500,          # 훈련 데이터셋을 총 500회 반복 실험. 단, 조기중지될 수 있음\n",
        "    validation_split=0.2,  \n",
        "        #validation data 분할 비율. 즉, 100개 중에서 20%인 20개를 validation용으로 분할\n",
        "     callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)],  \n",
        "        #'val_loss'를 monitor하여 감소하면 한 번 더 참고 조기중지\n",
        "    verbose=1)   # 전 과정을 화면에 출력(1) 또는 미출력(0) 모드\n",
        "\n",
        "# 테스트 데이터로 평가하기\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test_loss: ', score[0])\n",
        "print('test_acc: ', score[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0881 - accuracy: 0.3875 - val_loss: 1.1076 - val_accuracy: 0.2500\n",
            "Epoch 2/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0907 - accuracy: 0.3875 - val_loss: 1.1080 - val_accuracy: 0.2500\n",
            "Epoch 3/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0902 - accuracy: 0.3875 - val_loss: 1.1086 - val_accuracy: 0.2500\n",
            "Epoch 4/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0893 - accuracy: 0.3875 - val_loss: 1.1089 - val_accuracy: 0.2500\n",
            "Epoch 5/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0910 - accuracy: 0.3875 - val_loss: 1.1091 - val_accuracy: 0.2500\n",
            "Epoch 6/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0893 - accuracy: 0.3875 - val_loss: 1.1095 - val_accuracy: 0.2500\n",
            "Epoch 7/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0924 - accuracy: 0.3875 - val_loss: 1.1096 - val_accuracy: 0.2500\n",
            "Epoch 8/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0899 - accuracy: 0.3875 - val_loss: 1.1096 - val_accuracy: 0.2500\n",
            "Epoch 9/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0882 - accuracy: 0.3875 - val_loss: 1.1097 - val_accuracy: 0.2500\n",
            "Epoch 10/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0853 - accuracy: 0.3875 - val_loss: 1.1101 - val_accuracy: 0.2500\n",
            "Epoch 11/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0923 - accuracy: 0.3875 - val_loss: 1.1098 - val_accuracy: 0.2500\n",
            "Epoch 12/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0898 - accuracy: 0.3875 - val_loss: 1.1097 - val_accuracy: 0.2500\n",
            "Epoch 13/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0877 - accuracy: 0.3875 - val_loss: 1.1098 - val_accuracy: 0.2500\n",
            "Epoch 14/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0892 - accuracy: 0.3875 - val_loss: 1.1102 - val_accuracy: 0.2500\n",
            "Epoch 15/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0879 - accuracy: 0.3875 - val_loss: 1.1105 - val_accuracy: 0.2500\n",
            "Epoch 16/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0910 - accuracy: 0.3875 - val_loss: 1.1104 - val_accuracy: 0.2500\n",
            "Epoch 17/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0920 - accuracy: 0.3875 - val_loss: 1.1105 - val_accuracy: 0.2500\n",
            "Epoch 18/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0911 - accuracy: 0.3875 - val_loss: 1.1102 - val_accuracy: 0.2500\n",
            "Epoch 19/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0919 - accuracy: 0.3875 - val_loss: 1.1097 - val_accuracy: 0.2500\n",
            "Epoch 20/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0854 - accuracy: 0.3875 - val_loss: 1.1101 - val_accuracy: 0.2500\n",
            "Epoch 21/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0883 - accuracy: 0.3875 - val_loss: 1.1101 - val_accuracy: 0.2500\n",
            "Epoch 22/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0924 - accuracy: 0.3875 - val_loss: 1.1100 - val_accuracy: 0.2500\n",
            "Epoch 23/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0907 - accuracy: 0.3875 - val_loss: 1.1098 - val_accuracy: 0.2500\n",
            "Epoch 24/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0880 - accuracy: 0.3875 - val_loss: 1.1100 - val_accuracy: 0.2500\n",
            "Epoch 25/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0844 - accuracy: 0.3875 - val_loss: 1.1106 - val_accuracy: 0.2500\n",
            "Epoch 26/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0882 - accuracy: 0.3875 - val_loss: 1.1102 - val_accuracy: 0.2500\n",
            "Epoch 27/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0872 - accuracy: 0.3875 - val_loss: 1.1103 - val_accuracy: 0.2500\n",
            "Epoch 28/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0882 - accuracy: 0.3875 - val_loss: 1.1106 - val_accuracy: 0.2500\n",
            "Epoch 29/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0902 - accuracy: 0.3875 - val_loss: 1.1099 - val_accuracy: 0.2500\n",
            "Epoch 30/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0883 - accuracy: 0.3875 - val_loss: 1.1100 - val_accuracy: 0.2500\n",
            "Epoch 31/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0889 - accuracy: 0.3875 - val_loss: 1.1100 - val_accuracy: 0.2500\n",
            "Epoch 32/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0891 - accuracy: 0.3875 - val_loss: 1.1099 - val_accuracy: 0.2500\n",
            "Epoch 33/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0874 - accuracy: 0.3875 - val_loss: 1.1096 - val_accuracy: 0.2500\n",
            "Epoch 34/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0884 - accuracy: 0.3875 - val_loss: 1.1092 - val_accuracy: 0.2500\n",
            "Epoch 35/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.3875 - val_loss: 1.1088 - val_accuracy: 0.2500\n",
            "Epoch 36/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0850 - accuracy: 0.3875 - val_loss: 1.1088 - val_accuracy: 0.2500\n",
            "Epoch 37/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0872 - accuracy: 0.3875 - val_loss: 1.1084 - val_accuracy: 0.2500\n",
            "Epoch 38/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0898 - accuracy: 0.3875 - val_loss: 1.1080 - val_accuracy: 0.2500\n",
            "Epoch 39/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0818 - accuracy: 0.3875 - val_loss: 1.1082 - val_accuracy: 0.2500\n",
            "Epoch 40/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0842 - accuracy: 0.3875 - val_loss: 1.1084 - val_accuracy: 0.2500\n",
            "Epoch 41/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.3875 - val_loss: 1.1081 - val_accuracy: 0.2500\n",
            "Epoch 42/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0872 - accuracy: 0.3875 - val_loss: 1.1077 - val_accuracy: 0.2500\n",
            "Epoch 43/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0838 - accuracy: 0.3875 - val_loss: 1.1072 - val_accuracy: 0.2500\n",
            "Epoch 44/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0870 - accuracy: 0.3875 - val_loss: 1.1070 - val_accuracy: 0.2500\n",
            "Epoch 45/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0849 - accuracy: 0.3875 - val_loss: 1.1070 - val_accuracy: 0.2500\n",
            "Epoch 46/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0851 - accuracy: 0.3875 - val_loss: 1.1070 - val_accuracy: 0.2500\n",
            "Epoch 47/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0864 - accuracy: 0.3875 - val_loss: 1.1068 - val_accuracy: 0.2500\n",
            "Epoch 48/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0844 - accuracy: 0.3875 - val_loss: 1.1065 - val_accuracy: 0.2500\n",
            "Epoch 49/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0860 - accuracy: 0.3875 - val_loss: 1.1061 - val_accuracy: 0.2500\n",
            "Epoch 50/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0855 - accuracy: 0.3875 - val_loss: 1.1058 - val_accuracy: 0.2500\n",
            "Epoch 51/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0818 - accuracy: 0.3875 - val_loss: 1.1054 - val_accuracy: 0.2500\n",
            "Epoch 52/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.3875 - val_loss: 1.1052 - val_accuracy: 0.2500\n",
            "Epoch 53/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0850 - accuracy: 0.3875 - val_loss: 1.1049 - val_accuracy: 0.2500\n",
            "Epoch 54/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0831 - accuracy: 0.3875 - val_loss: 1.1047 - val_accuracy: 0.2500\n",
            "Epoch 55/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0833 - accuracy: 0.3875 - val_loss: 1.1045 - val_accuracy: 0.2500\n",
            "Epoch 56/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0792 - accuracy: 0.3875 - val_loss: 1.1042 - val_accuracy: 0.2500\n",
            "Epoch 57/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0782 - accuracy: 0.3875 - val_loss: 1.1037 - val_accuracy: 0.2500\n",
            "Epoch 58/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0781 - accuracy: 0.3875 - val_loss: 1.1032 - val_accuracy: 0.2500\n",
            "Epoch 59/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0843 - accuracy: 0.3875 - val_loss: 1.1030 - val_accuracy: 0.2500\n",
            "Epoch 60/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0826 - accuracy: 0.3875 - val_loss: 1.1022 - val_accuracy: 0.2500\n",
            "Epoch 61/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.3875 - val_loss: 1.1015 - val_accuracy: 0.2500\n",
            "Epoch 62/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0771 - accuracy: 0.3875 - val_loss: 1.1009 - val_accuracy: 0.2500\n",
            "Epoch 63/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0748 - accuracy: 0.3875 - val_loss: 1.1001 - val_accuracy: 0.2500\n",
            "Epoch 64/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0745 - accuracy: 0.3875 - val_loss: 1.0993 - val_accuracy: 0.2500\n",
            "Epoch 65/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0746 - accuracy: 0.3875 - val_loss: 1.0986 - val_accuracy: 0.2500\n",
            "Epoch 66/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0811 - accuracy: 0.3875 - val_loss: 1.0979 - val_accuracy: 0.2500\n",
            "Epoch 67/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0783 - accuracy: 0.3875 - val_loss: 1.0974 - val_accuracy: 0.2500\n",
            "Epoch 68/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0747 - accuracy: 0.3875 - val_loss: 1.0968 - val_accuracy: 0.2500\n",
            "Epoch 69/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0780 - accuracy: 0.3875 - val_loss: 1.0962 - val_accuracy: 0.2500\n",
            "Epoch 70/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0780 - accuracy: 0.3875 - val_loss: 1.0956 - val_accuracy: 0.2500\n",
            "Epoch 71/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0773 - accuracy: 0.3875 - val_loss: 1.0949 - val_accuracy: 0.2500\n",
            "Epoch 72/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0770 - accuracy: 0.3875 - val_loss: 1.0943 - val_accuracy: 0.2500\n",
            "Epoch 73/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0725 - accuracy: 0.3875 - val_loss: 1.0932 - val_accuracy: 0.2500\n",
            "Epoch 74/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0679 - accuracy: 0.3875 - val_loss: 1.0920 - val_accuracy: 0.2500\n",
            "Epoch 75/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.3875 - val_loss: 1.0911 - val_accuracy: 0.2500\n",
            "Epoch 76/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0682 - accuracy: 0.3875 - val_loss: 1.0900 - val_accuracy: 0.2500\n",
            "Epoch 77/500\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1.0700 - accuracy: 0.3875 - val_loss: 1.0892 - val_accuracy: 0.2500\n",
            "Epoch 78/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0702 - accuracy: 0.3875 - val_loss: 1.0884 - val_accuracy: 0.2500\n",
            "Epoch 79/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0655 - accuracy: 0.3875 - val_loss: 1.0869 - val_accuracy: 0.2500\n",
            "Epoch 80/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0656 - accuracy: 0.3875 - val_loss: 1.0858 - val_accuracy: 0.2500\n",
            "Epoch 81/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0637 - accuracy: 0.3875 - val_loss: 1.0847 - val_accuracy: 0.2500\n",
            "Epoch 82/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0743 - accuracy: 0.3875 - val_loss: 1.0840 - val_accuracy: 0.2500\n",
            "Epoch 83/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0605 - accuracy: 0.3875 - val_loss: 1.0827 - val_accuracy: 0.2500\n",
            "Epoch 84/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0605 - accuracy: 0.3875 - val_loss: 1.0816 - val_accuracy: 0.2500\n",
            "Epoch 85/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0581 - accuracy: 0.3875 - val_loss: 1.0802 - val_accuracy: 0.2500\n",
            "Epoch 86/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0625 - accuracy: 0.3875 - val_loss: 1.0791 - val_accuracy: 0.2500\n",
            "Epoch 87/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0613 - accuracy: 0.3875 - val_loss: 1.0779 - val_accuracy: 0.2500\n",
            "Epoch 88/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0647 - accuracy: 0.3875 - val_loss: 1.0769 - val_accuracy: 0.2500\n",
            "Epoch 89/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0543 - accuracy: 0.3875 - val_loss: 1.0755 - val_accuracy: 0.2500\n",
            "Epoch 90/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0629 - accuracy: 0.3875 - val_loss: 1.0744 - val_accuracy: 0.2500\n",
            "Epoch 91/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0619 - accuracy: 0.3875 - val_loss: 1.0731 - val_accuracy: 0.2500\n",
            "Epoch 92/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.3875 - val_loss: 1.0717 - val_accuracy: 0.2500\n",
            "Epoch 93/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0565 - accuracy: 0.3875 - val_loss: 1.0704 - val_accuracy: 0.2500\n",
            "Epoch 94/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0533 - accuracy: 0.3875 - val_loss: 1.0689 - val_accuracy: 0.2500\n",
            "Epoch 95/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0472 - accuracy: 0.3875 - val_loss: 1.0669 - val_accuracy: 0.2500\n",
            "Epoch 96/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0497 - accuracy: 0.3875 - val_loss: 1.0654 - val_accuracy: 0.2500\n",
            "Epoch 97/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0414 - accuracy: 0.3875 - val_loss: 1.0635 - val_accuracy: 0.2500\n",
            "Epoch 98/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0476 - accuracy: 0.3875 - val_loss: 1.0623 - val_accuracy: 0.2500\n",
            "Epoch 99/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0479 - accuracy: 0.3875 - val_loss: 1.0607 - val_accuracy: 0.2500\n",
            "Epoch 100/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0581 - accuracy: 0.3875 - val_loss: 1.0594 - val_accuracy: 0.2500\n",
            "Epoch 101/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0514 - accuracy: 0.3875 - val_loss: 1.0579 - val_accuracy: 0.2500\n",
            "Epoch 102/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0451 - accuracy: 0.3875 - val_loss: 1.0561 - val_accuracy: 0.2500\n",
            "Epoch 103/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0485 - accuracy: 0.3875 - val_loss: 1.0545 - val_accuracy: 0.2500\n",
            "Epoch 104/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0445 - accuracy: 0.3875 - val_loss: 1.0528 - val_accuracy: 0.2500\n",
            "Epoch 105/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.3875 - val_loss: 1.0509 - val_accuracy: 0.2500\n",
            "Epoch 106/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.3875 - val_loss: 1.0489 - val_accuracy: 0.2500\n",
            "Epoch 107/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0393 - accuracy: 0.3875 - val_loss: 1.0476 - val_accuracy: 0.2500\n",
            "Epoch 108/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0363 - accuracy: 0.3875 - val_loss: 1.0456 - val_accuracy: 0.2500\n",
            "Epoch 109/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0287 - accuracy: 0.3875 - val_loss: 1.0436 - val_accuracy: 0.2500\n",
            "Epoch 110/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0372 - accuracy: 0.3875 - val_loss: 1.0417 - val_accuracy: 0.2500\n",
            "Epoch 111/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.3875 - val_loss: 1.0399 - val_accuracy: 0.2500\n",
            "Epoch 112/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.3875 - val_loss: 1.0381 - val_accuracy: 0.2500\n",
            "Epoch 113/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.3875 - val_loss: 1.0359 - val_accuracy: 0.2500\n",
            "Epoch 114/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 1.0488 - accuracy: 0.3875 - val_loss: 1.0341 - val_accuracy: 0.2500\n",
            "Epoch 115/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0246 - accuracy: 0.3875 - val_loss: 1.0320 - val_accuracy: 0.2500\n",
            "Epoch 116/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0126 - accuracy: 0.4500 - val_loss: 1.0304 - val_accuracy: 0.2500\n",
            "Epoch 117/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0267 - accuracy: 0.3875 - val_loss: 1.0277 - val_accuracy: 0.2500\n",
            "Epoch 118/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0241 - accuracy: 0.3875 - val_loss: 1.0253 - val_accuracy: 0.2500\n",
            "Epoch 119/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0199 - accuracy: 0.3875 - val_loss: 1.0231 - val_accuracy: 0.2500\n",
            "Epoch 120/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0159 - accuracy: 0.4250 - val_loss: 1.0209 - val_accuracy: 0.2500\n",
            "Epoch 121/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0092 - accuracy: 0.3875 - val_loss: 1.0181 - val_accuracy: 0.2500\n",
            "Epoch 122/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0130 - accuracy: 0.4250 - val_loss: 1.0154 - val_accuracy: 0.2500\n",
            "Epoch 123/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0181 - accuracy: 0.4750 - val_loss: 1.0132 - val_accuracy: 0.2500\n",
            "Epoch 124/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0251 - accuracy: 0.5500 - val_loss: 1.0115 - val_accuracy: 0.2500\n",
            "Epoch 125/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0263 - accuracy: 0.4875 - val_loss: 1.0099 - val_accuracy: 0.2500\n",
            "Epoch 126/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9907 - accuracy: 0.6625 - val_loss: 1.0054 - val_accuracy: 0.2500\n",
            "Epoch 127/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0119 - accuracy: 0.5875 - val_loss: 1.0034 - val_accuracy: 0.2500\n",
            "Epoch 128/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0202 - accuracy: 0.5750 - val_loss: 1.0019 - val_accuracy: 0.2500\n",
            "Epoch 129/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0029 - accuracy: 0.6125 - val_loss: 0.9994 - val_accuracy: 0.2500\n",
            "Epoch 130/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0027 - accuracy: 0.6375 - val_loss: 0.9971 - val_accuracy: 0.2500\n",
            "Epoch 131/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0094 - accuracy: 0.6500 - val_loss: 0.9940 - val_accuracy: 0.4000\n",
            "Epoch 132/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9815 - accuracy: 0.6500 - val_loss: 0.9908 - val_accuracy: 0.6500\n",
            "Epoch 133/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9982 - accuracy: 0.6250 - val_loss: 0.9890 - val_accuracy: 0.7000\n",
            "Epoch 134/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0071 - accuracy: 0.6125 - val_loss: 0.9866 - val_accuracy: 0.6500\n",
            "Epoch 135/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 1.0059 - accuracy: 0.5875 - val_loss: 0.9848 - val_accuracy: 0.5000\n",
            "Epoch 136/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9812 - accuracy: 0.6625 - val_loss: 0.9808 - val_accuracy: 0.7000\n",
            "Epoch 137/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9954 - accuracy: 0.6000 - val_loss: 0.9782 - val_accuracy: 0.7000\n",
            "Epoch 138/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9859 - accuracy: 0.6000 - val_loss: 0.9777 - val_accuracy: 0.7000\n",
            "Epoch 139/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9863 - accuracy: 0.6500 - val_loss: 0.9736 - val_accuracy: 0.7000\n",
            "Epoch 140/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9843 - accuracy: 0.6250 - val_loss: 0.9711 - val_accuracy: 0.7000\n",
            "Epoch 141/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9778 - accuracy: 0.6000 - val_loss: 0.9679 - val_accuracy: 0.7000\n",
            "Epoch 142/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9843 - accuracy: 0.6125 - val_loss: 0.9666 - val_accuracy: 0.7000\n",
            "Epoch 143/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9856 - accuracy: 0.6375 - val_loss: 0.9636 - val_accuracy: 0.7000\n",
            "Epoch 144/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9659 - accuracy: 0.6500 - val_loss: 0.9597 - val_accuracy: 0.7000\n",
            "Epoch 145/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9694 - accuracy: 0.6500 - val_loss: 0.9561 - val_accuracy: 0.7000\n",
            "Epoch 146/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9665 - accuracy: 0.6000 - val_loss: 0.9538 - val_accuracy: 0.7000\n",
            "Epoch 147/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9568 - accuracy: 0.6125 - val_loss: 0.9507 - val_accuracy: 0.7000\n",
            "Epoch 148/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9703 - accuracy: 0.6000 - val_loss: 0.9478 - val_accuracy: 0.7000\n",
            "Epoch 149/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9708 - accuracy: 0.6375 - val_loss: 0.9471 - val_accuracy: 0.7000\n",
            "Epoch 150/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9436 - accuracy: 0.6500 - val_loss: 0.9420 - val_accuracy: 0.7000\n",
            "Epoch 151/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9610 - accuracy: 0.6375 - val_loss: 0.9388 - val_accuracy: 0.7000\n",
            "Epoch 152/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9584 - accuracy: 0.6250 - val_loss: 0.9366 - val_accuracy: 0.7000\n",
            "Epoch 153/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9476 - accuracy: 0.6250 - val_loss: 0.9333 - val_accuracy: 0.7000\n",
            "Epoch 154/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9558 - accuracy: 0.5500 - val_loss: 0.9324 - val_accuracy: 0.7000\n",
            "Epoch 155/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9435 - accuracy: 0.6125 - val_loss: 0.9268 - val_accuracy: 0.7000\n",
            "Epoch 156/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9276 - accuracy: 0.6000 - val_loss: 0.9233 - val_accuracy: 0.7000\n",
            "Epoch 157/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9332 - accuracy: 0.6625 - val_loss: 0.9201 - val_accuracy: 0.7000\n",
            "Epoch 158/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9263 - accuracy: 0.6375 - val_loss: 0.9174 - val_accuracy: 0.7500\n",
            "Epoch 159/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9592 - accuracy: 0.7375 - val_loss: 0.9140 - val_accuracy: 0.7500\n",
            "Epoch 160/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9130 - accuracy: 0.7500 - val_loss: 0.9099 - val_accuracy: 0.7500\n",
            "Epoch 161/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9166 - accuracy: 0.7125 - val_loss: 0.9063 - val_accuracy: 0.7500\n",
            "Epoch 162/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9230 - accuracy: 0.6875 - val_loss: 0.9035 - val_accuracy: 0.7500\n",
            "Epoch 163/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9488 - accuracy: 0.6750 - val_loss: 0.9004 - val_accuracy: 0.7500\n",
            "Epoch 164/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9141 - accuracy: 0.7750 - val_loss: 0.8969 - val_accuracy: 0.7500\n",
            "Epoch 165/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9434 - accuracy: 0.6125 - val_loss: 0.8944 - val_accuracy: 0.7500\n",
            "Epoch 166/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8993 - accuracy: 0.7375 - val_loss: 0.8914 - val_accuracy: 0.7000\n",
            "Epoch 167/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9349 - accuracy: 0.6875 - val_loss: 0.8882 - val_accuracy: 0.7500\n",
            "Epoch 168/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9345 - accuracy: 0.6625 - val_loss: 0.8851 - val_accuracy: 0.7500\n",
            "Epoch 169/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9154 - accuracy: 0.7000 - val_loss: 0.8817 - val_accuracy: 0.7500\n",
            "Epoch 170/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8661 - accuracy: 0.8125 - val_loss: 0.8777 - val_accuracy: 0.7500\n",
            "Epoch 171/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9170 - accuracy: 0.6875 - val_loss: 0.8751 - val_accuracy: 0.8500\n",
            "Epoch 172/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9130 - accuracy: 0.7125 - val_loss: 0.8744 - val_accuracy: 0.8500\n",
            "Epoch 173/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8834 - accuracy: 0.7875 - val_loss: 0.8679 - val_accuracy: 0.8500\n",
            "Epoch 174/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9019 - accuracy: 0.7625 - val_loss: 0.8654 - val_accuracy: 0.7500\n",
            "Epoch 175/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9216 - accuracy: 0.6625 - val_loss: 0.8620 - val_accuracy: 0.7500\n",
            "Epoch 176/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9257 - accuracy: 0.6750 - val_loss: 0.8592 - val_accuracy: 0.8500\n",
            "Epoch 177/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8851 - accuracy: 0.8000 - val_loss: 0.8557 - val_accuracy: 0.8500\n",
            "Epoch 178/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8830 - accuracy: 0.7375 - val_loss: 0.8530 - val_accuracy: 0.8500\n",
            "Epoch 179/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9130 - accuracy: 0.7125 - val_loss: 0.8513 - val_accuracy: 0.8500\n",
            "Epoch 180/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8725 - accuracy: 0.8125 - val_loss: 0.8483 - val_accuracy: 0.8500\n",
            "Epoch 181/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8791 - accuracy: 0.7625 - val_loss: 0.8440 - val_accuracy: 0.8500\n",
            "Epoch 182/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8766 - accuracy: 0.6625 - val_loss: 0.8402 - val_accuracy: 0.8500\n",
            "Epoch 183/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8740 - accuracy: 0.7625 - val_loss: 0.8365 - val_accuracy: 0.8500\n",
            "Epoch 184/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8560 - accuracy: 0.7375 - val_loss: 0.8323 - val_accuracy: 0.8500\n",
            "Epoch 185/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.7375 - val_loss: 0.8292 - val_accuracy: 0.8500\n",
            "Epoch 186/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.7000 - val_loss: 0.8272 - val_accuracy: 0.8500\n",
            "Epoch 187/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8950 - accuracy: 0.7125 - val_loss: 0.8244 - val_accuracy: 0.8500\n",
            "Epoch 188/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8879 - accuracy: 0.6625 - val_loss: 0.8235 - val_accuracy: 0.9000\n",
            "Epoch 189/500\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.8990 - accuracy: 0.7375 - val_loss: 0.8223 - val_accuracy: 0.9500\n",
            "Epoch 190/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.9024 - accuracy: 0.7000 - val_loss: 0.8170 - val_accuracy: 0.8500\n",
            "Epoch 191/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8813 - accuracy: 0.7000 - val_loss: 0.8164 - val_accuracy: 0.9500\n",
            "Epoch 192/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8569 - accuracy: 0.7375 - val_loss: 0.8104 - val_accuracy: 0.9000\n",
            "Epoch 193/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9231 - accuracy: 0.7375 - val_loss: 0.8080 - val_accuracy: 0.8500\n",
            "Epoch 194/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8518 - accuracy: 0.7750 - val_loss: 0.8045 - val_accuracy: 0.8500\n",
            "Epoch 195/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.8732 - accuracy: 0.7125 - val_loss: 0.8011 - val_accuracy: 0.8500\n",
            "Epoch 196/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8552 - accuracy: 0.7625 - val_loss: 0.7977 - val_accuracy: 0.8500\n",
            "Epoch 197/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8220 - accuracy: 0.7750 - val_loss: 0.7942 - val_accuracy: 0.8500\n",
            "Epoch 198/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8735 - accuracy: 0.7500 - val_loss: 0.7939 - val_accuracy: 0.8500\n",
            "Epoch 199/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8185 - accuracy: 0.7750 - val_loss: 0.7871 - val_accuracy: 0.8500\n",
            "Epoch 200/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8562 - accuracy: 0.7125 - val_loss: 0.7845 - val_accuracy: 0.8500\n",
            "Epoch 201/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8583 - accuracy: 0.7625 - val_loss: 0.7806 - val_accuracy: 0.8500\n",
            "Epoch 202/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8505 - accuracy: 0.6875 - val_loss: 0.7769 - val_accuracy: 0.8500\n",
            "Epoch 203/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8749 - accuracy: 0.7375 - val_loss: 0.7752 - val_accuracy: 0.9000\n",
            "Epoch 204/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8849 - accuracy: 0.7250 - val_loss: 0.7726 - val_accuracy: 0.8500\n",
            "Epoch 205/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8385 - accuracy: 0.7375 - val_loss: 0.7692 - val_accuracy: 0.9000\n",
            "Epoch 206/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8547 - accuracy: 0.7500 - val_loss: 0.7713 - val_accuracy: 0.9500\n",
            "Epoch 207/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8274 - accuracy: 0.8000 - val_loss: 0.7636 - val_accuracy: 0.8500\n",
            "Epoch 208/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8916 - accuracy: 0.6375 - val_loss: 0.7608 - val_accuracy: 0.9000\n",
            "Epoch 209/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8069 - accuracy: 0.8125 - val_loss: 0.7566 - val_accuracy: 0.8500\n",
            "Epoch 210/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8581 - accuracy: 0.7375 - val_loss: 0.7566 - val_accuracy: 0.9500\n",
            "Epoch 211/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8276 - accuracy: 0.7500 - val_loss: 0.7502 - val_accuracy: 0.9000\n",
            "Epoch 212/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.6625 - val_loss: 0.7507 - val_accuracy: 0.9500\n",
            "Epoch 213/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8624 - accuracy: 0.7000 - val_loss: 0.7489 - val_accuracy: 0.9500\n",
            "Epoch 214/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7625 - accuracy: 0.8125 - val_loss: 0.7438 - val_accuracy: 0.9500\n",
            "Epoch 215/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7824 - accuracy: 0.8125 - val_loss: 0.7376 - val_accuracy: 0.9500\n",
            "Epoch 216/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7887 - accuracy: 0.7875 - val_loss: 0.7394 - val_accuracy: 0.9500\n",
            "Epoch 217/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8405 - accuracy: 0.7375 - val_loss: 0.7370 - val_accuracy: 0.9500\n",
            "Epoch 218/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8011 - accuracy: 0.8000 - val_loss: 0.7289 - val_accuracy: 0.9500\n",
            "Epoch 219/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8172 - accuracy: 0.7625 - val_loss: 0.7284 - val_accuracy: 0.9500\n",
            "Epoch 220/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7730 - accuracy: 0.8250 - val_loss: 0.7219 - val_accuracy: 0.9000\n",
            "Epoch 221/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8252 - accuracy: 0.7125 - val_loss: 0.7191 - val_accuracy: 0.9500\n",
            "Epoch 222/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8268 - accuracy: 0.7250 - val_loss: 0.7185 - val_accuracy: 0.9500\n",
            "Epoch 223/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8543 - accuracy: 0.7375 - val_loss: 0.7176 - val_accuracy: 0.9500\n",
            "Epoch 224/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7575 - accuracy: 0.8250 - val_loss: 0.7112 - val_accuracy: 0.9500\n",
            "Epoch 225/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8166 - accuracy: 0.7500 - val_loss: 0.7093 - val_accuracy: 0.9500\n",
            "Epoch 226/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8529 - accuracy: 0.6750 - val_loss: 0.7086 - val_accuracy: 0.9500\n",
            "Epoch 227/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7725 - accuracy: 0.8125 - val_loss: 0.7020 - val_accuracy: 0.9500\n",
            "Epoch 228/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.8000 - val_loss: 0.7004 - val_accuracy: 0.9500\n",
            "Epoch 229/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8128 - accuracy: 0.7750 - val_loss: 0.6998 - val_accuracy: 0.9500\n",
            "Epoch 230/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7858 - accuracy: 0.7750 - val_loss: 0.6942 - val_accuracy: 0.9500\n",
            "Epoch 231/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8725 - accuracy: 0.7250 - val_loss: 0.6951 - val_accuracy: 0.9500\n",
            "Epoch 232/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7555 - accuracy: 0.7750 - val_loss: 0.6903 - val_accuracy: 0.9500\n",
            "Epoch 233/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7845 - accuracy: 0.7250 - val_loss: 0.6855 - val_accuracy: 0.9500\n",
            "Epoch 234/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.7250 - val_loss: 0.6849 - val_accuracy: 0.9500\n",
            "Epoch 235/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8275 - accuracy: 0.7375 - val_loss: 0.6822 - val_accuracy: 0.9500\n",
            "Epoch 236/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7528 - accuracy: 0.7875 - val_loss: 0.6795 - val_accuracy: 0.9500\n",
            "Epoch 237/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7819 - accuracy: 0.7750 - val_loss: 0.6752 - val_accuracy: 0.9500\n",
            "Epoch 238/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7287 - accuracy: 0.8375 - val_loss: 0.6710 - val_accuracy: 0.8500\n",
            "Epoch 239/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7948 - accuracy: 0.7750 - val_loss: 0.6687 - val_accuracy: 0.9500\n",
            "Epoch 240/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8513 - accuracy: 0.6375 - val_loss: 0.6721 - val_accuracy: 0.9500\n",
            "Epoch 241/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7406 - accuracy: 0.8500 - val_loss: 0.6655 - val_accuracy: 0.9500\n",
            "Epoch 242/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7614 - accuracy: 0.7625 - val_loss: 0.6651 - val_accuracy: 0.9500\n",
            "Epoch 243/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8004 - accuracy: 0.7500 - val_loss: 0.6688 - val_accuracy: 0.9500\n",
            "Epoch 244/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.8375 - val_loss: 0.6599 - val_accuracy: 0.9500\n",
            "Epoch 245/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.8125 - val_loss: 0.6531 - val_accuracy: 0.9500\n",
            "Epoch 246/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7495 - accuracy: 0.8125 - val_loss: 0.6503 - val_accuracy: 0.9500\n",
            "Epoch 247/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7850 - accuracy: 0.7125 - val_loss: 0.6513 - val_accuracy: 0.9500\n",
            "Epoch 248/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7465 - accuracy: 0.8375 - val_loss: 0.6468 - val_accuracy: 0.9500\n",
            "Epoch 249/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.7625 - val_loss: 0.6479 - val_accuracy: 0.9500\n",
            "Epoch 250/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.7850 - accuracy: 0.7375 - val_loss: 0.6466 - val_accuracy: 0.9500\n",
            "Epoch 251/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7800 - accuracy: 0.7375 - val_loss: 0.6464 - val_accuracy: 0.9500\n",
            "Epoch 252/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.8125 - val_loss: 0.6419 - val_accuracy: 0.9500\n",
            "Epoch 253/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7654 - accuracy: 0.7875 - val_loss: 0.6390 - val_accuracy: 0.9500\n",
            "Epoch 254/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8064 - accuracy: 0.7250 - val_loss: 0.6419 - val_accuracy: 0.9500\n",
            "Epoch 255/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7833 - accuracy: 0.8375 - val_loss: 0.6370 - val_accuracy: 0.9500\n",
            "Epoch 256/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8197 - accuracy: 0.7250 - val_loss: 0.6392 - val_accuracy: 0.9500\n",
            "Epoch 257/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7084 - accuracy: 0.8375 - val_loss: 0.6312 - val_accuracy: 0.9500\n",
            "Epoch 258/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8207 - accuracy: 0.7500 - val_loss: 0.6371 - val_accuracy: 0.9500\n",
            "Epoch 259/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6968 - accuracy: 0.8750 - val_loss: 0.6267 - val_accuracy: 0.9500\n",
            "Epoch 260/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7802 - accuracy: 0.7625 - val_loss: 0.6281 - val_accuracy: 0.9500\n",
            "Epoch 261/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6812 - accuracy: 0.8625 - val_loss: 0.6217 - val_accuracy: 0.9500\n",
            "Epoch 262/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7564 - accuracy: 0.7625 - val_loss: 0.6197 - val_accuracy: 0.9500\n",
            "Epoch 263/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8243 - accuracy: 0.7250 - val_loss: 0.6185 - val_accuracy: 0.9500\n",
            "Epoch 264/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7928 - accuracy: 0.7625 - val_loss: 0.6189 - val_accuracy: 0.9500\n",
            "Epoch 265/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7618 - accuracy: 0.7500 - val_loss: 0.6187 - val_accuracy: 0.9500\n",
            "Epoch 266/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.7750 - val_loss: 0.6161 - val_accuracy: 0.9500\n",
            "Epoch 267/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7718 - accuracy: 0.7625 - val_loss: 0.6149 - val_accuracy: 0.9500\n",
            "Epoch 268/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.8375 - val_loss: 0.6098 - val_accuracy: 0.9500\n",
            "Epoch 269/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.8250 - val_loss: 0.6069 - val_accuracy: 0.9500\n",
            "Epoch 270/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7177 - accuracy: 0.7500 - val_loss: 0.6048 - val_accuracy: 0.9500\n",
            "Epoch 271/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.7875 - val_loss: 0.6028 - val_accuracy: 0.9500\n",
            "Epoch 272/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7634 - accuracy: 0.7250 - val_loss: 0.6044 - val_accuracy: 0.9500\n",
            "Epoch 273/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7600 - accuracy: 0.7375 - val_loss: 0.6024 - val_accuracy: 0.9500\n",
            "Epoch 274/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7738 - accuracy: 0.7750 - val_loss: 0.5959 - val_accuracy: 0.9500\n",
            "Epoch 275/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7620 - accuracy: 0.7250 - val_loss: 0.5983 - val_accuracy: 0.9500\n",
            "Epoch 276/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.8073 - accuracy: 0.7375 - val_loss: 0.5971 - val_accuracy: 0.9500\n",
            "Epoch 277/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7875 - val_loss: 0.5950 - val_accuracy: 0.9500\n",
            "Epoch 278/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.7625 - val_loss: 0.5953 - val_accuracy: 0.9500\n",
            "Epoch 279/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7854 - accuracy: 0.7750 - val_loss: 0.5884 - val_accuracy: 0.9500\n",
            "Epoch 280/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.7500 - val_loss: 0.5871 - val_accuracy: 0.9500\n",
            "Epoch 281/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7100 - accuracy: 0.7750 - val_loss: 0.5865 - val_accuracy: 0.9500\n",
            "Epoch 282/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7291 - accuracy: 0.8000 - val_loss: 0.5845 - val_accuracy: 0.9500\n",
            "Epoch 283/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7893 - accuracy: 0.7500 - val_loss: 0.5848 - val_accuracy: 0.9500\n",
            "Epoch 284/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8232 - accuracy: 0.7250 - val_loss: 0.5899 - val_accuracy: 0.9500\n",
            "Epoch 285/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.8875 - val_loss: 0.5789 - val_accuracy: 0.9500\n",
            "Epoch 286/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.8000 - val_loss: 0.5789 - val_accuracy: 0.9500\n",
            "Epoch 287/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.7500 - val_loss: 0.5769 - val_accuracy: 0.9500\n",
            "Epoch 288/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7520 - accuracy: 0.7875 - val_loss: 0.5741 - val_accuracy: 0.9500\n",
            "Epoch 289/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7849 - accuracy: 0.7250 - val_loss: 0.5785 - val_accuracy: 0.9500\n",
            "Epoch 290/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6582 - accuracy: 0.8625 - val_loss: 0.5710 - val_accuracy: 0.9500\n",
            "Epoch 291/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.8250 - val_loss: 0.5680 - val_accuracy: 0.9500\n",
            "Epoch 292/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.7500 - val_loss: 0.5672 - val_accuracy: 0.9500\n",
            "Epoch 293/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.8125 - val_loss: 0.5678 - val_accuracy: 0.9500\n",
            "Epoch 294/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.8125 - val_loss: 0.5635 - val_accuracy: 0.9500\n",
            "Epoch 295/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.7875 - val_loss: 0.5625 - val_accuracy: 0.9500\n",
            "Epoch 296/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.7750 - val_loss: 0.5624 - val_accuracy: 0.9500\n",
            "Epoch 297/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.8000 - val_loss: 0.5585 - val_accuracy: 0.9500\n",
            "Epoch 298/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.8000 - val_loss: 0.5557 - val_accuracy: 0.9500\n",
            "Epoch 299/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7560 - accuracy: 0.7875 - val_loss: 0.5560 - val_accuracy: 0.9500\n",
            "Epoch 300/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.8000 - val_loss: 0.5540 - val_accuracy: 0.9500\n",
            "Epoch 301/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.7875 - val_loss: 0.5527 - val_accuracy: 0.9500\n",
            "Epoch 302/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7121 - accuracy: 0.7250 - val_loss: 0.5537 - val_accuracy: 0.9500\n",
            "Epoch 303/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.8125 - val_loss: 0.5518 - val_accuracy: 0.9500\n",
            "Epoch 304/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.8000 - val_loss: 0.5500 - val_accuracy: 0.9500\n",
            "Epoch 305/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.7125 - val_loss: 0.5484 - val_accuracy: 0.9500\n",
            "Epoch 306/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.7875 - val_loss: 0.5484 - val_accuracy: 0.9500\n",
            "Epoch 307/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.8000 - val_loss: 0.5506 - val_accuracy: 0.9500\n",
            "Epoch 308/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7438 - accuracy: 0.7625 - val_loss: 0.5452 - val_accuracy: 0.9500\n",
            "Epoch 309/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.7500 - val_loss: 0.5455 - val_accuracy: 0.9500\n",
            "Epoch 310/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5969 - accuracy: 0.8375 - val_loss: 0.5442 - val_accuracy: 0.9500\n",
            "Epoch 311/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7279 - accuracy: 0.7750 - val_loss: 0.5415 - val_accuracy: 0.9500\n",
            "Epoch 312/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.8000 - val_loss: 0.5381 - val_accuracy: 0.9500\n",
            "Epoch 313/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.8375 - val_loss: 0.5345 - val_accuracy: 0.9500\n",
            "Epoch 314/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.8375 - val_loss: 0.5360 - val_accuracy: 0.9500\n",
            "Epoch 315/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.7750 - val_loss: 0.5321 - val_accuracy: 0.9500\n",
            "Epoch 316/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.7875 - val_loss: 0.5354 - val_accuracy: 0.9500\n",
            "Epoch 317/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6730 - accuracy: 0.8250 - val_loss: 0.5324 - val_accuracy: 0.9500\n",
            "Epoch 318/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.7625 - val_loss: 0.5341 - val_accuracy: 0.9500\n",
            "Epoch 319/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7110 - accuracy: 0.8250 - val_loss: 0.5314 - val_accuracy: 0.9500\n",
            "Epoch 320/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7650 - accuracy: 0.7000 - val_loss: 0.5382 - val_accuracy: 0.9500\n",
            "Epoch 321/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.8500 - val_loss: 0.5353 - val_accuracy: 0.9500\n",
            "Epoch 322/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.8125 - val_loss: 0.5313 - val_accuracy: 0.9500\n",
            "Epoch 323/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.7625 - val_loss: 0.5334 - val_accuracy: 0.9500\n",
            "Epoch 324/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7997 - accuracy: 0.7375 - val_loss: 0.5244 - val_accuracy: 0.9500\n",
            "Epoch 325/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.7625 - val_loss: 0.5250 - val_accuracy: 0.9500\n",
            "Epoch 326/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.8500 - val_loss: 0.5202 - val_accuracy: 0.9500\n",
            "Epoch 327/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6458 - accuracy: 0.7875 - val_loss: 0.5174 - val_accuracy: 0.9500\n",
            "Epoch 328/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7062 - accuracy: 0.7625 - val_loss: 0.5220 - val_accuracy: 0.9500\n",
            "Epoch 329/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.7210 - accuracy: 0.7375 - val_loss: 0.5224 - val_accuracy: 0.9500\n",
            "Epoch 330/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7033 - accuracy: 0.7750 - val_loss: 0.5180 - val_accuracy: 0.9500\n",
            "Epoch 331/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.8125 - val_loss: 0.5169 - val_accuracy: 0.9500\n",
            "Epoch 332/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.8500 - val_loss: 0.5161 - val_accuracy: 0.9500\n",
            "Epoch 333/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.8500 - val_loss: 0.5136 - val_accuracy: 0.9500\n",
            "Epoch 334/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.8625 - val_loss: 0.5117 - val_accuracy: 0.9500\n",
            "Epoch 335/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.8375 - val_loss: 0.5097 - val_accuracy: 0.9500\n",
            "Epoch 336/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.7875 - val_loss: 0.5162 - val_accuracy: 0.9500\n",
            "Epoch 337/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.8375 - val_loss: 0.5060 - val_accuracy: 0.9500\n",
            "Epoch 338/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.8000 - val_loss: 0.5091 - val_accuracy: 0.9500\n",
            "Epoch 339/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.8625 - val_loss: 0.5117 - val_accuracy: 0.9500\n",
            "Epoch 340/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.8000 - val_loss: 0.5058 - val_accuracy: 0.9500\n",
            "Epoch 341/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6591 - accuracy: 0.8125 - val_loss: 0.5028 - val_accuracy: 0.9500\n",
            "Epoch 342/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.8250 - val_loss: 0.5087 - val_accuracy: 0.9500\n",
            "Epoch 343/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.8250 - val_loss: 0.5161 - val_accuracy: 0.9500\n",
            "Epoch 344/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7493 - accuracy: 0.7250 - val_loss: 0.5050 - val_accuracy: 0.9500\n",
            "Epoch 345/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.8000 - val_loss: 0.5043 - val_accuracy: 0.9500\n",
            "Epoch 346/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.7750 - val_loss: 0.5033 - val_accuracy: 0.9500\n",
            "Epoch 347/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.7625 - val_loss: 0.5041 - val_accuracy: 0.9500\n",
            "Epoch 348/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.8125 - val_loss: 0.4980 - val_accuracy: 0.9500\n",
            "Epoch 349/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.8125 - val_loss: 0.4917 - val_accuracy: 0.9500\n",
            "Epoch 350/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.8000 - val_loss: 0.4961 - val_accuracy: 0.9500\n",
            "Epoch 351/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.7875 - val_loss: 0.4978 - val_accuracy: 0.9500\n",
            "Epoch 352/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.8500 - val_loss: 0.5017 - val_accuracy: 0.9500\n",
            "Epoch 353/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7750 - val_loss: 0.4968 - val_accuracy: 0.9500\n",
            "Epoch 354/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.8375 - val_loss: 0.4948 - val_accuracy: 0.9500\n",
            "Epoch 355/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.7875 - val_loss: 0.4966 - val_accuracy: 0.9500\n",
            "Epoch 356/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7480 - accuracy: 0.7750 - val_loss: 0.4941 - val_accuracy: 0.9500\n",
            "Epoch 357/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7537 - accuracy: 0.7000 - val_loss: 0.4974 - val_accuracy: 0.9500\n",
            "Epoch 358/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.8000 - val_loss: 0.4897 - val_accuracy: 0.9500\n",
            "Epoch 359/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6677 - accuracy: 0.8375 - val_loss: 0.4950 - val_accuracy: 0.9500\n",
            "Epoch 360/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.8250 - val_loss: 0.4933 - val_accuracy: 0.9500\n",
            "Epoch 361/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7411 - accuracy: 0.7750 - val_loss: 0.4970 - val_accuracy: 0.9500\n",
            "Epoch 362/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.8250 - val_loss: 0.4958 - val_accuracy: 0.9500\n",
            "Epoch 363/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.7750 - val_loss: 0.5019 - val_accuracy: 0.9500\n",
            "Epoch 364/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7637 - accuracy: 0.7500 - val_loss: 0.4870 - val_accuracy: 0.9500\n",
            "Epoch 365/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.8250 - val_loss: 0.4868 - val_accuracy: 0.9500\n",
            "Epoch 366/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.8125 - val_loss: 0.4825 - val_accuracy: 0.9500\n",
            "Epoch 367/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.8250 - val_loss: 0.4761 - val_accuracy: 0.9500\n",
            "Epoch 368/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6427 - accuracy: 0.8125 - val_loss: 0.4760 - val_accuracy: 0.9500\n",
            "Epoch 369/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.8250 - val_loss: 0.4734 - val_accuracy: 0.9500\n",
            "Epoch 370/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.7875 - val_loss: 0.4812 - val_accuracy: 0.9500\n",
            "Epoch 371/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6828 - accuracy: 0.8125 - val_loss: 0.4786 - val_accuracy: 0.9500\n",
            "Epoch 372/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6612 - accuracy: 0.8000 - val_loss: 0.4788 - val_accuracy: 0.9500\n",
            "Epoch 373/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.7250 - val_loss: 0.4756 - val_accuracy: 0.9500\n",
            "Epoch 374/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.8125 - val_loss: 0.4714 - val_accuracy: 0.9500\n",
            "Epoch 375/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.7750 - val_loss: 0.4725 - val_accuracy: 0.9500\n",
            "Epoch 376/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.8125 - val_loss: 0.4731 - val_accuracy: 0.9500\n",
            "Epoch 377/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.8750 - val_loss: 0.4690 - val_accuracy: 0.9500\n",
            "Epoch 378/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.8250 - val_loss: 0.4701 - val_accuracy: 0.9500\n",
            "Epoch 379/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6827 - accuracy: 0.8000 - val_loss: 0.4692 - val_accuracy: 0.9500\n",
            "Epoch 380/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6124 - accuracy: 0.8375 - val_loss: 0.4664 - val_accuracy: 0.9500\n",
            "Epoch 381/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7507 - accuracy: 0.7125 - val_loss: 0.4709 - val_accuracy: 0.9500\n",
            "Epoch 382/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.7750 - val_loss: 0.4715 - val_accuracy: 0.9500\n",
            "Epoch 383/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.8750 - val_loss: 0.4641 - val_accuracy: 0.9500\n",
            "Epoch 384/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.7625 - val_loss: 0.4638 - val_accuracy: 0.9500\n",
            "Epoch 385/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.8000 - val_loss: 0.4642 - val_accuracy: 0.9500\n",
            "Epoch 386/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.7251 - accuracy: 0.7750 - val_loss: 0.4631 - val_accuracy: 0.9500\n",
            "Epoch 387/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.7875 - val_loss: 0.4625 - val_accuracy: 0.9500\n",
            "Epoch 388/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.8500 - val_loss: 0.4616 - val_accuracy: 0.9500\n",
            "Epoch 389/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.8500 - val_loss: 0.4619 - val_accuracy: 0.9500\n",
            "Epoch 390/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.7500 - val_loss: 0.4645 - val_accuracy: 0.9500\n",
            "Epoch 391/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.8125 - val_loss: 0.4676 - val_accuracy: 0.9500\n",
            "Epoch 392/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.7875 - val_loss: 0.4615 - val_accuracy: 0.9500\n",
            "Epoch 393/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.8125 - val_loss: 0.4570 - val_accuracy: 0.9500\n",
            "Epoch 394/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7069 - accuracy: 0.8125 - val_loss: 0.4602 - val_accuracy: 0.9500\n",
            "Epoch 395/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.7750 - val_loss: 0.4581 - val_accuracy: 0.9500\n",
            "Epoch 396/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.8250 - val_loss: 0.4534 - val_accuracy: 0.9500\n",
            "Epoch 397/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7750 - val_loss: 0.4561 - val_accuracy: 0.9500\n",
            "Epoch 398/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.7875 - val_loss: 0.4662 - val_accuracy: 0.9500\n",
            "Epoch 399/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.7750 - val_loss: 0.4600 - val_accuracy: 0.9500\n",
            "Epoch 400/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.8125 - val_loss: 0.4522 - val_accuracy: 0.9500\n",
            "Epoch 401/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.8375 - val_loss: 0.4495 - val_accuracy: 0.9500\n",
            "Epoch 402/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.8500 - val_loss: 0.4514 - val_accuracy: 0.9500\n",
            "Epoch 403/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.8125 - val_loss: 0.4515 - val_accuracy: 0.9500\n",
            "Epoch 404/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.8500 - val_loss: 0.4557 - val_accuracy: 0.9500\n",
            "Epoch 405/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.8625 - val_loss: 0.4506 - val_accuracy: 0.9500\n",
            "Epoch 406/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7500 - val_loss: 0.4514 - val_accuracy: 0.9500\n",
            "Epoch 407/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.8250 - val_loss: 0.4463 - val_accuracy: 0.9500\n",
            "Epoch 408/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.8125 - val_loss: 0.4479 - val_accuracy: 0.9500\n",
            "Epoch 409/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8856 - accuracy: 0.6500 - val_loss: 0.4513 - val_accuracy: 0.9500\n",
            "Epoch 410/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.8375 - val_loss: 0.4432 - val_accuracy: 0.9500\n",
            "Epoch 411/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7650 - accuracy: 0.7250 - val_loss: 0.4441 - val_accuracy: 0.9500\n",
            "Epoch 412/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.7500 - val_loss: 0.4481 - val_accuracy: 0.9500\n",
            "Epoch 413/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.8250 - val_loss: 0.4502 - val_accuracy: 0.9500\n",
            "Epoch 414/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5820 - accuracy: 0.8250 - val_loss: 0.4430 - val_accuracy: 0.9500\n",
            "Epoch 415/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7674 - accuracy: 0.7750 - val_loss: 0.4438 - val_accuracy: 0.9500\n",
            "Epoch 416/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.8750 - val_loss: 0.4401 - val_accuracy: 0.9500\n",
            "Epoch 417/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.8750 - val_loss: 0.4475 - val_accuracy: 0.9500\n",
            "Epoch 418/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.7250 - val_loss: 0.4459 - val_accuracy: 0.9500\n",
            "Epoch 419/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.7875 - val_loss: 0.4428 - val_accuracy: 0.9500\n",
            "Epoch 420/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.8250 - val_loss: 0.4380 - val_accuracy: 0.9500\n",
            "Epoch 421/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.8250 - val_loss: 0.4424 - val_accuracy: 0.9500\n",
            "Epoch 422/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.7875 - val_loss: 0.4376 - val_accuracy: 0.9500\n",
            "Epoch 423/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.7750 - val_loss: 0.4377 - val_accuracy: 0.9500\n",
            "Epoch 424/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5678 - accuracy: 0.8250 - val_loss: 0.4340 - val_accuracy: 0.9500\n",
            "Epoch 425/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.8875 - val_loss: 0.4361 - val_accuracy: 0.9500\n",
            "Epoch 426/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.8375 - val_loss: 0.4339 - val_accuracy: 0.9500\n",
            "Epoch 427/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.8375 - val_loss: 0.4304 - val_accuracy: 0.9500\n",
            "Epoch 428/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.7750 - val_loss: 0.4290 - val_accuracy: 0.9500\n",
            "Epoch 429/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.8500 - val_loss: 0.4298 - val_accuracy: 0.9500\n",
            "Epoch 430/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.8250 - val_loss: 0.4276 - val_accuracy: 0.9500\n",
            "Epoch 431/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.7750 - val_loss: 0.4247 - val_accuracy: 0.9500\n",
            "Epoch 432/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.8000 - val_loss: 0.4311 - val_accuracy: 0.9500\n",
            "Epoch 433/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.8250 - val_loss: 0.4270 - val_accuracy: 0.9500\n",
            "Epoch 434/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.7250 - val_loss: 0.4318 - val_accuracy: 0.9500\n",
            "Epoch 435/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.8500 - val_loss: 0.4420 - val_accuracy: 0.9500\n",
            "Epoch 436/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.7125 - val_loss: 0.4295 - val_accuracy: 0.9500\n",
            "Epoch 437/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.8000 - val_loss: 0.4304 - val_accuracy: 0.9500\n",
            "Epoch 438/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.8000 - val_loss: 0.4384 - val_accuracy: 0.9500\n",
            "Epoch 439/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.7875 - val_loss: 0.4383 - val_accuracy: 0.9500\n",
            "Epoch 440/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.8500 - val_loss: 0.4484 - val_accuracy: 0.9500\n",
            "Epoch 441/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.8375 - val_loss: 0.4383 - val_accuracy: 0.9500\n",
            "Epoch 442/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6219 - accuracy: 0.8250 - val_loss: 0.4310 - val_accuracy: 0.9500\n",
            "Epoch 443/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.6403 - accuracy: 0.7750 - val_loss: 0.4316 - val_accuracy: 0.9500\n",
            "Epoch 444/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.8500 - val_loss: 0.4323 - val_accuracy: 0.9500\n",
            "Epoch 445/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6348 - accuracy: 0.8125 - val_loss: 0.4261 - val_accuracy: 0.9500\n",
            "Epoch 446/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7875 - val_loss: 0.4286 - val_accuracy: 0.9500\n",
            "Epoch 447/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.8625 - val_loss: 0.4218 - val_accuracy: 0.9500\n",
            "Epoch 448/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.7750 - val_loss: 0.4233 - val_accuracy: 0.9500\n",
            "Epoch 449/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.8125 - val_loss: 0.4269 - val_accuracy: 0.9500\n",
            "Epoch 450/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.7750 - val_loss: 0.4269 - val_accuracy: 0.9500\n",
            "Epoch 451/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.8125 - val_loss: 0.4211 - val_accuracy: 0.9500\n",
            "Epoch 452/500\n",
            "27/27 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.8250 - val_loss: 0.4230 - val_accuracy: 0.9500\n",
            "Epoch 453/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7792 - accuracy: 0.7500 - val_loss: 0.4253 - val_accuracy: 0.9500\n",
            "Epoch 454/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.7750 - val_loss: 0.4155 - val_accuracy: 0.9500\n",
            "Epoch 455/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.8250 - val_loss: 0.4158 - val_accuracy: 0.9500\n",
            "Epoch 456/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.8125 - val_loss: 0.4198 - val_accuracy: 0.9500\n",
            "Epoch 457/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.8500 - val_loss: 0.4193 - val_accuracy: 0.9500\n",
            "Epoch 458/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.8125 - val_loss: 0.4134 - val_accuracy: 0.9500\n",
            "Epoch 459/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.9125 - val_loss: 0.4143 - val_accuracy: 0.9500\n",
            "Epoch 460/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.8000 - val_loss: 0.4189 - val_accuracy: 0.9500\n",
            "Epoch 461/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.8750 - val_loss: 0.4163 - val_accuracy: 0.9500\n",
            "Epoch 462/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.8375 - val_loss: 0.4159 - val_accuracy: 0.9500\n",
            "Epoch 463/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.7625 - val_loss: 0.4171 - val_accuracy: 0.9500\n",
            "Epoch 464/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6031 - accuracy: 0.8125 - val_loss: 0.4160 - val_accuracy: 0.9500\n",
            "Epoch 465/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6132 - accuracy: 0.8500 - val_loss: 0.4223 - val_accuracy: 0.9500\n",
            "Epoch 466/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.8375 - val_loss: 0.4193 - val_accuracy: 0.9500\n",
            "Epoch 467/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.8500 - val_loss: 0.4139 - val_accuracy: 0.9500\n",
            "Epoch 468/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.8375 - val_loss: 0.4185 - val_accuracy: 0.9500\n",
            "Epoch 469/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.7500 - val_loss: 0.4120 - val_accuracy: 0.9500\n",
            "Epoch 470/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.8125 - val_loss: 0.4075 - val_accuracy: 0.9500\n",
            "Epoch 471/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7873 - accuracy: 0.7500 - val_loss: 0.4122 - val_accuracy: 0.9500\n",
            "Epoch 472/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6544 - accuracy: 0.8000 - val_loss: 0.4116 - val_accuracy: 0.9500\n",
            "Epoch 473/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.8250 - val_loss: 0.4040 - val_accuracy: 0.9500\n",
            "Epoch 474/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6060 - accuracy: 0.8125 - val_loss: 0.4029 - val_accuracy: 0.9500\n",
            "Epoch 475/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.8750 - val_loss: 0.4057 - val_accuracy: 0.9500\n",
            "Epoch 476/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7305 - accuracy: 0.7750 - val_loss: 0.4035 - val_accuracy: 0.9500\n",
            "Epoch 477/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6662 - accuracy: 0.8500 - val_loss: 0.4058 - val_accuracy: 0.9500\n",
            "Epoch 478/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.7250 - val_loss: 0.4100 - val_accuracy: 0.9500\n",
            "Epoch 479/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7854 - accuracy: 0.8000 - val_loss: 0.4077 - val_accuracy: 0.9500\n",
            "Epoch 480/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.8125 - val_loss: 0.4069 - val_accuracy: 0.9500\n",
            "Epoch 481/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.8000 - val_loss: 0.4049 - val_accuracy: 0.9500\n",
            "Epoch 482/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.7375 - val_loss: 0.4018 - val_accuracy: 0.9500\n",
            "Epoch 483/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.8250 - val_loss: 0.3943 - val_accuracy: 0.9500\n",
            "Epoch 484/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7750 - val_loss: 0.3928 - val_accuracy: 0.9500\n",
            "Epoch 485/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.8080 - accuracy: 0.7000 - val_loss: 0.3979 - val_accuracy: 0.9500\n",
            "Epoch 486/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.8375 - val_loss: 0.4027 - val_accuracy: 0.9500\n",
            "Epoch 487/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.7750 - val_loss: 0.3944 - val_accuracy: 0.9500\n",
            "Epoch 488/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.8375 - val_loss: 0.3993 - val_accuracy: 0.9500\n",
            "Epoch 489/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.7124 - accuracy: 0.7625 - val_loss: 0.4005 - val_accuracy: 0.9500\n",
            "Epoch 490/500\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.8250 - val_loss: 0.4003 - val_accuracy: 0.9500\n",
            "Epoch 491/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.8250 - val_loss: 0.3928 - val_accuracy: 0.9500\n",
            "Epoch 492/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.8250 - val_loss: 0.3995 - val_accuracy: 0.9500\n",
            "Epoch 493/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7718 - accuracy: 0.7375 - val_loss: 0.3979 - val_accuracy: 0.9500\n",
            "Epoch 494/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.8125 - val_loss: 0.4034 - val_accuracy: 0.9500\n",
            "Epoch 495/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.8500 - val_loss: 0.3963 - val_accuracy: 0.9500\n",
            "Epoch 496/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.8375 - val_loss: 0.3927 - val_accuracy: 0.9500\n",
            "Epoch 497/500\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.7191 - accuracy: 0.7125 - val_loss: 0.3954 - val_accuracy: 0.9500\n",
            "Epoch 498/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.8125 - val_loss: 0.4060 - val_accuracy: 0.9500\n",
            "Epoch 499/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.4901 - accuracy: 0.8750 - val_loss: 0.3960 - val_accuracy: 0.9500\n",
            "Epoch 500/500\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.8000 - val_loss: 0.3896 - val_accuracy: 0.9500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.4197 - accuracy: 0.9600\n",
            "test_loss:  0.41973862051963806\n",
            "test_acc:  0.9599999785423279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVZ2sf6Gb5Y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a53ea7-1042-4fae-861a-00d3988715ca"
      },
      "source": [
        "hist.history.keys()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hh1NwcAwLtVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d88e328c-1609-4c32-9dad-70606ecabc5d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0LNN770LtVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd61e19a-6b06-43fe-9cf6-719f1c06c2ce"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 40        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 15        \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91\n",
            "Trainable params: 91\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap06VxZI5Aog",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bc683a-7034-4c34-b124-4ffa1dca5fc0"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.19696689, -0.6041742 , -0.14081043, -0.45291257,  0.23733564,\n",
              "         -0.69069076, -0.70110285, -0.27177227],\n",
              "        [ 0.10682273,  0.05524576,  0.34421784,  0.07068348, -0.46610862,\n",
              "         -0.47056347,  1.4429115 , -0.25654265],\n",
              "        [-0.19099534, -0.5187931 , -0.2565647 , -0.00770074,  2.8656583 ,\n",
              "          0.22244549, -3.5223744 ,  0.55393547],\n",
              "        [-0.23968321, -0.40523368, -0.57773435,  0.24585366,  3.8554285 ,\n",
              "          0.03590441, -3.8569388 ,  0.5749569 ]], dtype=float32),\n",
              " array([ 0.        ,  0.        ,  0.        ,  0.        , -0.02964206,\n",
              "         0.        ,  0.14541265, -0.00316226], dtype=float32),\n",
              " array([[-0.28180546, -0.5524012 , -0.17222565, -0.27138776],\n",
              "        [ 0.6576349 ,  0.69200045, -0.1328907 ,  0.04136848],\n",
              "        [ 0.54625267, -0.6115737 ,  0.31654948,  0.5313706 ],\n",
              "        [ 0.23094147, -0.1253668 , -0.10000163, -0.21747553],\n",
              "        [-3.5900347 , -0.49037033, -0.6989807 , -0.518823  ],\n",
              "        [ 0.36868054, -0.46719545,  0.53440076,  0.1932944 ],\n",
              "        [ 6.4652376 , -0.2865055 , -0.41231942,  1.2857386 ],\n",
              "        [-0.6869889 , -0.58036864,  0.58381444,  0.2427922 ]],\n",
              "       dtype=float32),\n",
              " array([0.3289667 , 0.        , 0.        , 0.05179477], dtype=float32),\n",
              " array([[ 3.5949092 , -6.192935  , -0.39321136],\n",
              "        [-0.44589707, -0.8707641 , -0.14916718],\n",
              "        [-0.31904948,  0.7841642 ,  0.18550491],\n",
              "        [ 1.2495023 , -1.2748471 ,  0.31083223]], dtype=float32),\n",
              " array([-2.1700535 ,  0.9148898 ,  0.40342683], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "nhPK4V6nLtVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f333665d-2aab-42ec-f7d6-c9df553753f1"
      },
      "source": [
        "model.save(dir+\"dnn_iris.h5\")\n",
        "print(\"Saved model to disk.\")\n",
        "\n",
        "from numpy import loadtxt\n",
        "from tensorflow.python.keras.models import load_model\n",
        "\n",
        "# 저장된 모델 읽어오기\n",
        "loaded_model = load_model(dir+\"dnn_iris.h5\")\n",
        "model.summary()\n",
        "\n",
        "# 모델을 평가하기\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('test_loss: ', score[0])\n",
        "print('test_acc: ', score[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 40        \n",
            "                                                                 \n",
            " activation (Activation)     (None, 8)                 0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8)                 0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 15        \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 91\n",
            "Trainable params: 91\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.9600\n",
            "test_loss:  0.41973862051963806\n",
            "test_acc:  0.9599999785423279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8sQr21XLtVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbbb4cc-1fbd-47bf-981d-3940e54de65d"
      },
      "source": [
        "# X_test 샘플들의 클래스 예측하기\n",
        "y_prob = model.predict(X_test)    # X_test의 출력값 확인하기\n",
        "print(y_prob)\n",
        "\n",
        "y_class = y_prob.argmax(axis=-1)  # X_test의 클래스 예측하기\n",
        "y_class"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "[[7.90339410e-01 1.14216388e-03 2.08518401e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [2.79671066e-02 6.06476426e-01 3.65556449e-01]\n",
            " [3.66496444e-01 4.52908687e-02 5.88212729e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [8.32138956e-01 6.15086756e-04 1.67245880e-01]\n",
            " [8.76623511e-01 2.67813477e-04 1.23108670e-01]\n",
            " [8.47566605e-01 4.72780841e-04 1.51960701e-01]\n",
            " [4.24262993e-02 5.18266082e-01 4.39307600e-01]\n",
            " [2.78416146e-02 6.07421994e-01 3.64736408e-01]\n",
            " [8.29282254e-02 3.55608433e-01 5.61463237e-01]\n",
            " [8.33232105e-01 6.04166009e-04 1.66163862e-01]\n",
            " [1.68152556e-01 1.81481317e-01 6.50366127e-01]\n",
            " [8.20945740e-01 7.34734233e-04 1.78319424e-01]\n",
            " [5.68258911e-02 4.49786782e-01 4.93387371e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [3.07229795e-02 5.87631762e-01 3.81645262e-01]\n",
            " [1.64300293e-01 1.86747283e-01 6.48952484e-01]\n",
            " [1.83469415e-01 1.62171707e-01 6.54358983e-01]\n",
            " [8.39617372e-01 5.42954716e-04 1.59839615e-01]\n",
            " [8.30373466e-01 6.33004121e-04 1.68993458e-01]\n",
            " [8.33001673e-01 6.06457761e-04 1.66391969e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [2.79995184e-02 6.06232703e-01 3.65767807e-01]\n",
            " [2.78231818e-02 6.07561052e-01 3.64615768e-01]\n",
            " [8.50484550e-01 4.48633975e-04 1.49066821e-01]\n",
            " [9.76804346e-02 3.13989013e-01 5.88330507e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [1.81010470e-01 1.65101990e-01 6.53887630e-01]\n",
            " [8.47649992e-01 4.72078071e-04 1.51877910e-01]\n",
            " [1.14490516e-01 2.73851722e-01 6.11657798e-01]\n",
            " [1.45681441e-01 2.14801177e-01 6.39517367e-01]\n",
            " [8.21823597e-01 7.24898535e-04 1.77451551e-01]\n",
            " [8.33892405e-01 5.97617880e-04 1.65509850e-01]\n",
            " [4.15891446e-02 5.22743344e-01 4.35667515e-01]\n",
            " [4.77833189e-02 4.90984619e-01 4.61232066e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [4.85009439e-02 4.87490267e-01 4.64008749e-01]\n",
            " [3.13296430e-02 5.83636224e-01 3.85034084e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [2.78734695e-02 6.07181787e-01 3.64944816e-01]\n",
            " [8.34750175e-01 5.89210656e-04 1.64660618e-01]\n",
            " [2.47844964e-01 1.02550291e-01 6.49604738e-01]\n",
            " [2.77950708e-02 6.07773304e-01 3.64431649e-01]\n",
            " [4.80166636e-02 4.89848435e-01 4.62134868e-01]\n",
            " [7.76051104e-01 1.37748942e-03 2.22571433e-01]\n",
            " [1.21697694e-01 2.58625358e-01 6.19676948e-01]\n",
            " [2.78618876e-02 6.07269049e-01 3.64869088e-01]\n",
            " [2.79422849e-02 6.06663227e-01 3.65394443e-01]\n",
            " [8.31396699e-01 6.22586638e-04 1.67980701e-01]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 2, 1, 0, 0, 0, 1, 1, 2, 0, 2, 0, 2, 1, 1, 2, 2, 0, 0, 0,\n",
              "       1, 1, 1, 0, 2, 1, 2, 0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1,\n",
              "       1, 0, 2, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Xez1yYLtV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654395ea-f8b3-4ad0-f068-cf4904b4d34a"
      },
      "source": [
        "# 새로운 샘플의 클래스 예측하기\n",
        "X_new = [5.7, 3.8, 1.7, 0.3]\n",
        "X_new[0] /= 100   # normalization\n",
        "X_new[1] /= 200   # normalization\n",
        "X_new[2] /= 200   # normalization\n",
        "X_new[3] /= 200   # normalization\n",
        "print(X_new)\n",
        "\n",
        "y_prob = model.predict([X_new]) # X_new의 출력값 확인하기\n",
        "y_pred = y_prob.argmax()        # X_new의 클래스 예측하기\n",
        "print(y_prob, y_pred)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.057, 0.019, 0.0085, 0.0015]\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "[[0.7903394  0.00114216 0.2085184 ]] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDjOYxUzLtVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f490077-0e80-46a2-e693-b1afcdbf34b3"
      },
      "source": [
        "type(X_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOdX9FRmLtVz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3e7cf843-509f-493b-efa1-862869768a40"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width\n",
              "100         0.057       0.0190        0.0085       0.0015\n",
              "101         0.072       0.0180        0.0305       0.0125\n",
              "102         0.063       0.0145        0.0280       0.0090\n",
              "103         0.049       0.0120        0.0165       0.0050\n",
              "104         0.077       0.0150        0.0305       0.0115"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a60ebaa4-42d8-4a19-99f8-f257e983a86e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.057</td>\n",
              "      <td>0.0190</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>0.072</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>0.0125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.063</td>\n",
              "      <td>0.0145</td>\n",
              "      <td>0.0280</td>\n",
              "      <td>0.0090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.049</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0165</td>\n",
              "      <td>0.0050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.077</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>0.0115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a60ebaa4-42d8-4a19-99f8-f257e983a86e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a60ebaa4-42d8-4a19-99f8-f257e983a86e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a60ebaa4-42d8-4a19-99f8-f257e983a86e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaOIG8Kaovrc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc9bfe5-3916-4800-e849-217e9b06c4fe"
      },
      "source": [
        "X_test.head(5).index.tolist()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[100, 101, 102, 103, 104]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfXV29CxuGk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ddc172-4ede-4b06-aaeb-ae63e32592af"
      },
      "source": [
        "X_test0 = X_test.loc[100]\n",
        "print(X_test0); print()\n",
        "\n",
        "X_test_li = list(X_test0)\n",
        "y_prob = model.predict([X_test_li])  # model.predict([[0.69, 0.55]])\n",
        "y_pred = y_prob.argmax()\n",
        "print(y_prob, y_pred)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal_length    0.0570\n",
            "sepal_width     0.0190\n",
            "petal_length    0.0085\n",
            "petal_width     0.0015\n",
            "Name: 100, dtype: float64\n",
            "\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "[[0.7903394  0.00114216 0.2085184 ]] 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flB-FoC2LtV0"
      },
      "source": [
        "def predict_bmi(X_new):\n",
        "  y_prob = model.predict([X_new])\n",
        "  y_pred = y_prob.argmax()\n",
        "  print(X_new, y_prob, y_pred, sep='\\t')"
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}